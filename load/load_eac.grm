// groovy / gremlin script to load EAC-CPF relations into a graph database

// set EAC_DIR XTF_BASE_URL GRAPH_DB GRAPH_ML

def env = System.getenv()

// directory to troll
def data_root = env['EAC_DIR'] ?: "./data"

// paths for output files can be set with environmental variables, or use these defaults
def database_path = env['GRAPH_DB'] ?: "./neo4j-db"
def graphML_file = env['GRAPH_ML'] ?: "./graphML.xml"
def gml_file = env['GRAPH_GML'] ?: "./graph.gml"
def GraphSON_file = env['GRAPH_JSON'] ?: "./GraphSON.json"
def BATCH_SIZE = 10000

// does the input even exist ?
def dir = new File(data_root)
if (!(dir.exists()) ){ println data_root + " not found"; System.exit(1) }

// create graph
def base = new Neo4jGraph(database_path)

base.createKeyIndex('identity', Vertex.class)
base.createKeyIndex('sourceEADurlIndex', Vertex.class)
base.createKeyIndex('recordId', Vertex.class)

g = new BatchGraph(base, VertexIDType.STRING, BATCH_SIZE);
g.setVertexIdKey('recordId');
g.setLoadingFromScratch(false);

vCount = 0

// first loop; define vertex for each name / EAC file
dir.eachFile{file->
  vCount++
  def eac = new XmlSlurper().parse(file).declareNamespace(xlink: 'http://www.w3.org/1999/xlink')
  // xpath: /eac-cpf/cpfDescription/identity[1]/nameEntry/part
  def fromName = eac.cpfDescription.identity[0].nameEntry[0].part
  def entityType = eac.cpfDescription.identity[0].entityType
  // eac.cpfDescription.control.sources.source now has VIAF and worldcat links
    
  // def existDates = eac.cpfDescription.description[0].existDates
  def creatorOf = ''
  def referencedIn = ''
  def sameAs = ''
  def recordId = eac.control.recordId[0].text()
  def otherRecordId = eac.control.otherRecordId.findAll{ it.@localType="mergedCPF" }
  eac.cpfDescription.relations."*".findAll { it."@xlink:href" != '' }.each {  
    if (it."@xlink:arcrole".toString().contains("creatorOf")) {
      creatorOf = creatorOf + it."@xlink:href" + "\n"
    }
    if (it."@xlink:arcrole".toString().contains("referencedIn")) {
      referencedIn = referencedIn + it."@xlink:href" + "\n"
    }
    if (it."@xlink:arcrole".toString().contains("sameAs")) {
      sameAs = sameAs + it."@xlink:href" + "\n"
    }
  }
  Vertex vertex = g.addVertex(recordId as String)
  vertex["filename"] = file.getName()
  vertex["identity"] = fromName as String
  vertex["entityType"] = entityType as String
 
  if (creatorOf != '')     { 
    vertex["creatorOf"]  = creatorOf.tokenize("\n") 
  }
  if (referencedIn != '')  { 
    vertex["referencedIn"]  = referencedIn.tokenize("\n") 
  }
  if (recordId != '')      { 
    vertex["recordId"] = recordId
  }
  if (otherRecordId != '') {
    otherRecordId.each {
    // vertex["otherRecordId"] = otherRecordId
    }
  }
  if (sameAs != '') {
    vertex["sameAs"]  = sameAs.tokenize("\n") 
  }
  print vCount
  print vertex["identity"]
  println vertex
}

println "end of first loop"
vCount = 0
eCount = 0

// second loop; create the edges
dir.eachFile{file->

  vCount++
  // first, get the vertex for this file
  def eac = new XmlSlurper().parse(file).declareNamespace(xlink: 'http://www.w3.org/1999/xlink')
  def from_recordId = eac.control.recordId[0].text()
  def from_name = eac.cpfDescription.identity[0].nameEntry[0].part

  // now, process all related names
  eac.cpfDescription.relations.cpfRelation.each {
    def to_recordId = it."@xlink:href"
    def arcrole = it."@xlink:arcrole"
    def to_name = it."relationEntry"

    from_node = g.getVertex(from_recordId as String)
    to_node = g.getVertex(to_recordId as String)

    if (to_node) {
      eCount++ 
      def e = g.addEdge(null, from_node, to_node, arcrole as String)

      // and add some properties to the edge
      e.setProperty("to_name", to_name as String)
      e.setProperty("to_recordId", to_recordId as String)
      e.setProperty("from_name", from_name as String)
      e.setProperty("from_recordId", from_recordId as String)
      println "\"${vCount}, ${eCount} ${from_name}\" ${arcrole} \"${to_name}\"; ${from_recordId}->${to_recordId}"
    }

  }
}


println "compute popularity"
// pre compute popularity score
def counter = 1
for (z in base.V ) { 
  z.score = z.out.count() 
  if (counter % BATCH_SIZE == 0) {
    base.commit()
  }
}
base.commit()

println "output searlized versions"
// output searlized versions
GraphMLWriter.outputGraph(base, new FileOutputStream(graphML_file))
GraphSONWriter.outputGraph(base, new FileOutputStream(GraphSON_file))
GMLWriter.outputGraph(base, new FileOutputStream(gml_file))

println "shutdown"
// neo4j likes to be shutdown graceful like
base.shutdown()
